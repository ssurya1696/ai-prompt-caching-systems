{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e2c6a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import time\n",
    "from typing import Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "load_dotenv(override=True)\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\",temperature=0,api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77bd4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterministicPromptCache:\n",
    "    def __init__(self):\n",
    "        self.cache: Dict[str, Dict[str, Any]] = {}\n",
    "        self.metrics = {\n",
    "            \"hits\": 0,\n",
    "            \"misses\": 0,\n",
    "            \"total_requests\": 0\n",
    "        }\n",
    "\n",
    "    def _hash_prompt(self, prompt: str) -> str:\n",
    "        return hashlib.sha256(prompt.encode()).hexdigest()\n",
    "\n",
    "    def get(self, prompt: str):\n",
    "        self.metrics[\"total_requests\"] += 1\n",
    "        key = self._hash_prompt(prompt)\n",
    "\n",
    "        if key in self.cache:\n",
    "            self.metrics[\"hits\"] += 1\n",
    "            return self.cache[key][\"response\"]\n",
    "        else:\n",
    "            self.metrics[\"misses\"] += 1\n",
    "            return None\n",
    "\n",
    "    def set(self, prompt: str, response: str):\n",
    "        key = self._hash_prompt(prompt)\n",
    "        self.cache[key] = {\n",
    "            \"response\": response,\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "\n",
    "    def stats(self):\n",
    "        hit_rate = (\n",
    "            self.metrics[\"hits\"] / self.metrics[\"total_requests\"]\n",
    "            if self.metrics[\"total_requests\"] > 0\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            **self.metrics,\n",
    "            \"hit_rate\": round(hit_rate, 2)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626fdada",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = DeterministicPromptCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaaeed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cached_llm_call(prompt: str):\n",
    "\n",
    "    cached_response = cache.get(prompt)\n",
    "\n",
    "    if cached_response:\n",
    "        print(\"Cache HIT\")\n",
    "        return cached_response\n",
    "\n",
    "    print(\"Cache MISS — Calling LLM\")\n",
    "\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    output = response.content\n",
    "\n",
    "    cache.set(prompt, output)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dccae59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_latency(prompt: str):\n",
    "\n",
    "    start = time.time()\n",
    "    result = cached_llm_call(prompt)\n",
    "    end = time.time()\n",
    "\n",
    "    latency = round(end - start, 3)\n",
    "\n",
    "    print(f\"\\nLatency: {latency} seconds\\n\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658128e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Call (Expected MISS)\n",
      "Cache MISS — Calling LLM\n",
      "\n",
      "Latency: 4.426 seconds\n",
      "\n",
      "Second Call (Expected HIT)\n",
      "Cache HIT\n",
      "\n",
      "Latency: 0.0 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Artificial intelligence is the field of computer science focused on creating systems that can perform tasks that normally require human intelligence, such as learning, reasoning, and understanding language. Most modern AI uses machine learning, where algorithms learn from large datasets to improve their performance and adapt to new tasks, enabling applications like voice assistants, image recognition, and autonomous vehicles.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Explain AI in 2 sentences\"\n",
    "\n",
    "print(\"First Call (Expected MISS)\")\n",
    "measure_latency(prompt)\n",
    "\n",
    "print(\"Second Call (Expected HIT)\")\n",
    "measure_latency(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
